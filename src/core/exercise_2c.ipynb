{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fde0378",
   "metadata": {},
   "source": [
    "## Exercise 2c)\n",
    "\n",
    "In this notebook, we compute the testing MSE with the use of PyTorch, for the same model architectures and gradient descent methods as in the code in the regression analysis exercise 2b. \n",
    "\n",
    "**NOTE** One of the authors (Frederik) had trouble with importing torch with the virtual environment used in this project. This worked just fine for the other author (Heine). If you have a computer that runs into a problem with this, then it might help to create a separate virtual environment and install all of the libraries from the requirements file. Doing this always worked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644905b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_FROM_FILE = True   # load data from file, so the bottlenecks of the program run in just a few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d5efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.utils import skip_if, generate_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.style.use('./utils/_plot_style.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c01fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Use device of the acceleratorif it is available; else, use cpu\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca9ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "np.random.seed(124)\n",
    "\n",
    "n = 300\n",
    "x, y = generate_dataset(num=n)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.2,random_state=44)\n",
    "num_nodes = 50\n",
    "num_hidden_layers = [1,2]\n",
    "\n",
    "# Define training methods\n",
    "training_methods = [\n",
    "    \"SGD\",\n",
    "    \"GD\",\n",
    "]\n",
    "\n",
    "# Step methods\n",
    "step_methods = [\n",
    "    \"RMSprop\", \n",
    "    \"ADAM\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1876a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset tensors and loaders from the training and testing data\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32).to(device).float()\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device).float()\n",
    "x_test_tensor  = torch.tensor(x_test, dtype=torch.float32).to(device).float()\n",
    "y_test_tensor  = torch.tensor(y_test, dtype=torch.long).to(device).float()\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader_SGD = DataLoader(train_dataset, batch_size=60, shuffle=True)  # train_loader for stochastic gradient descent\n",
    "train_loader_GD = DataLoader(train_dataset, shuffle=False)    # train_loader for plain gradient descent\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define class for PyTorch neural network\n",
    "\n",
    "class NeuralNetwork_regression(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Feedforward neural network with PyTorch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_nodes : int\n",
    "        Number of nodes in each layer. \n",
    "    num_hidden_layers: int \n",
    "        Number of hidden layers in the model. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,num_nodes,num_hidden_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        model_layers = [nn.Linear(1,num_nodes),nn.Sigmoid()]\n",
    "        for i in range(num_hidden_layers-1): \n",
    "            model_layers.append(nn.Linear(num_nodes,num_nodes))\n",
    "            model_layers.append(nn.Sigmoid())\n",
    "        model_layers.append(nn.Linear(num_nodes,1))\n",
    "\n",
    "        self.linear_stack = nn.Sequential(*model_layers)\n",
    "\n",
    "    def forward(self, x):   # forward pass of the model\n",
    "        out = self.linear_stack(x)\n",
    "        return out\n",
    "    \n",
    "    def testing_MSE(self):  # return testing MSE\n",
    "        with torch.no_grad():  # disable gradient calculation for evaluation \n",
    "            input, target = test_dataset.tensors\n",
    "            output = self.linear_stack(input)\n",
    "        return torch.mean((target - output)**2)/len(target)\n",
    "            \n",
    "    \n",
    "    def train_model_regression(self,lr=0.01, num_epochs=3000, lambd=0,training_method = \"SGD\",step_method = \"ADAM\"):   # train NN model for regression, and return testing MSE\n",
    "        criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "        if training_method == \"SGD\": \n",
    "            loader = train_loader_SGD\n",
    "            n_batches = 5   # define number of batches, so the learning rate can be divided by it (gives correct correspondence with our neural network code)\n",
    "        else: \n",
    "            loader = train_loader_GD\n",
    "            n_batches = 1\n",
    "\n",
    "        if step_method == \"ADAM\":\n",
    "            optimizer = optim.Adam(self.parameters(), lr=lr/n_batches, weight_decay=lambd) # lambd is regularization parameter for L2 regularization\n",
    "        if step_method==\"RMSprop\": \n",
    "            optimizer = optim.RMSprop(self.parameters(), alpha = 0.9,lr=lr/n_batches, weight_decay=lambd) # lambd is regularization parameter for L2 regularization\n",
    "\n",
    "        for _ in range(num_epochs):\n",
    "            self.train()  # set model to training mode\n",
    "\n",
    "            for input, target in loader: \n",
    "                optimizer.zero_grad()            # reset gradients to zero\n",
    "                outputs = self.linear_stack(input)          # forward pass: compute predictions\n",
    "                loss = criterion(outputs,target)  # compute MSE\n",
    "                loss.backward()                 # backpropagate to compute gradients\n",
    "                optimizer.step()                # update weights using SGD step \n",
    "\n",
    "        return self.testing_MSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98846c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data for the best learning rates for SGD and GD from exercise 2b. \n",
    "\n",
    "filepath_1 = \"../data/best_learning_rate_SGD_final.npy\"\n",
    "filepath_2 = \"../data/best_learning_rate_GD_final.npy\"\n",
    "\n",
    "best_learning_rates_SGD = np.load(filepath_1)\n",
    "best_learning_rates_GD = np.load(filepath_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip_if LOAD_FROM_FILE\n",
    "\n",
    "n_learning_rates = 9\n",
    "num_iterations = 3000\n",
    "pytorch_mse_data = np.zeros((len(num_hidden_layers), len(training_methods),len(step_methods)))\n",
    "\n",
    "# Analyze pytorch testing mse vs. number of hidden layers, training methods and step methods \n",
    "for i in range(len(num_hidden_layers)):\n",
    "    print(num_hidden_layers[i])\n",
    "    for j, training_method_name in enumerate(training_methods):\n",
    "        for l, step_method_name in enumerate(step_methods): \n",
    "            print(\".\", end=\"\")\n",
    "            np.random.seed(124)\n",
    "            torch.manual_seed(124)\n",
    "\n",
    "            if training_method_name == \"SGD\": \n",
    "                best_lr = best_learning_rates_SGD\n",
    "            else: \n",
    "                best_lr = best_learning_rates_GD\n",
    "\n",
    "            model = NeuralNetwork_regression(num_nodes, num_hidden_layers[i]).to(device)  # define PyTorch neural network\n",
    "            mse_data = model.train_model_regression(lr = best_lr[i,l],training_method = training_method_name,step_method = step_method_name)  # find testing MSE\n",
    "            pytorch_mse_data[i][j][l] = mse_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../data/regression_mse_data_pytorch.npy\"\n",
    "#np.save(filepath, pytorch_mse_data)\n",
    "if LOAD_FROM_FILE:\n",
    "    pytorch_mse_data = np.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34000167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch MSE for SGD:  [[2.00000959e-05 2.80611516e-06]\n",
      " [6.76921445e-06 2.63497259e-06]]\n",
      "PyTorch MSE for GD:  [[4.41806858e-09 5.74487694e-06]\n",
      " [3.23084848e-08 4.10083931e-06]]\n"
     ]
    }
   ],
   "source": [
    "# Print PyTorch testing MSE for SGD and GD\n",
    "\n",
    "print(\"PyTorch MSE for SGD: \",pytorch_mse_data[:,0,:]) \n",
    "print(\"PyTorch MSE for GD: \",pytorch_mse_data[:,1,:]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchfix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
